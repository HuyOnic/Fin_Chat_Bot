import pandas as pd
import requests
from sentence_transformers import SentenceTransformer, util
from tqdm import tqdm
from openai import OpenAI
import os
from .perplexity_test import compute_perplexity

summarize_model = OpenAI(
    # model=os.getenv("LLM_MODEL_NAME"),
    base_url=os.getenv("OPENAI_API_BASE_URL", "http://localhost:8000/v1"),
    api_key="EMPTY"
)
# Load m√¥ h√¨nh embedding
model = SentenceTransformer("BAAI/bge-m3")

def summarize_text(context):
    response = summarize_model.chat.completions.create(
        model=os.getenv("LLM_MODEL_NAME"),
        messages=[
            {"role": "system", "content": "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI gi·ªèi t√≥m t·∫Øt c√°c n·ªôi dung v·ªÅ t√†i ch√≠nh."},
            {"role": "user", "content": f"H√£y t√≥m t·∫Øt ng·∫Øn g·ªçn nh·ªØng s·ªë  li·ªáu trong n·ªôi dung sau b·∫±ng Ti·∫øng Vi·ªát, kh√¥ng s·ª≠ d·ª•ng Ti·∫øng Anh:\n\n{context}"}
        ],
        temperature=0.5,
        max_tokens=512
    )
    return response.choices[0].message.content

def senmatic_similarity_test():
    # Load file CSV (ƒë·∫£m b·∫£o c√≥ c·ªôt 'question', 'answer')
    df = pd.read_csv("/home/goline/huy/quant_chat_bot/LLM_Project/data/output_test_v1.csv")  # üîÅ thay b·∫±ng t√™n file th·∫≠t c·ªßa b·∫°n
    result_df = df[["intent", "question", "answer"]].copy().rename(columns={"answer": "expected_answer"})

    result_df["predicted_answer"] = ""
    result_df["summarize_expected_answer"] = result_df["expected_answer"].copy()
    result_df["similarity"] = 0.0

    # L·∫∑p qua t·ª´ng c√¢u h·ªèi
    for idx, row in tqdm(df.iterrows(), total=len(df)):
        question = str(row["question"])
        expected_answer = str(row["answer"])
        predicted_answer = ""

        try:
            # G·ªçi API Chat c·∫£ local model 
            response = requests.post(
                "http://localhost:8081/test_chat",
                headers={"accept": "application/json", "Content-Type": "application/json"},
                json={"message": question},
                timeout=20
            )
            if response.status_code == 200:
                predicted_answer = response.json().get("message", "")
        except Exception as e:
            print(f"‚ùå L·ªói API cho c√¢u h·ªèi: {question} ‚Üí {e}")

        result_df.at[idx, "predicted_answer"] = predicted_answer

        # T√≠nh cosine similarity n·∫øu c√≥ d·ªØ li·ªáu
        if predicted_answer.strip():
            if len(expected_answer) > 200:
                expected_answer = summarize_text(expected_answer)
                result_df.at[idx, "summarize_expected_answer"] = expected_answer
            
            if len(predicted_answer) > 200:
                predicted_answer = summarize_text(predicted_answer)

            emb1 = model.encode(expected_answer, convert_to_tensor=True)
            emb2 = model.encode(predicted_answer, convert_to_tensor=True)
            similarity = util.cos_sim(emb1, emb2).item()
        else:
            similarity = 0.0

        # Ghi l·∫°i
        result_df.at[idx, "summarize_predicted_answer"] = predicted_answer
        result_df.at[idx, "similarity"] = similarity

    # L∆∞u ra file m·ªõi
    columns = ["intent", "question", "expected_answer", "predicted_answer", "summarize_expected_answer", "summarize_predicted_answer", "similarity"]
    result_df[columns].to_csv("/home/goline/huy/quant_chat_bot/LLM_Project/data/similarity_results.csv", index=False)
    print("SENTIMENT SECORE:", similarity)
    print("‚úÖ ƒê√£ ghi k·∫øt qu·∫£ v√†o data/similarity_results.csv")

if __name__=="__main__":
    senmatic_similarity_test()